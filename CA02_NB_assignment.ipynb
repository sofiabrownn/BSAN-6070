{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iCZYXwtCsL_y"
   },
   "source": [
    "CA02: This is a eMail Spam Classifers that uses Naive Bayes supervised machine learning algorithm. \n",
    "\n",
    "In this assignment you will ...\n",
    "1. Complete the code such a way that it works correctly with this given parts of the program.\n",
    "2. Explain as clearly as possible what each part of the code is doing. Use \"Markdown\" texts and code commenting to explain the code\n",
    "\n",
    "IMPORTANT NOTE:\n",
    "\n",
    "The path of your data folders 'train-mails' and 'test-mails' must be './train-mails' and './test-mails'. This means you must have your .ipynb file and these folders in the SAME FOLDER in your laptop or Google Drive. The reason for doing this is, this way the peer reviewes and I would be able to run your code from our computers using this exact same relative path, irrespective of our folder hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4p_DvtT7sOIr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Import all other necessary libraries. Your code below ...\n",
    "import sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jjKF0nIMwz8_"
   },
   "outputs": [],
   "source": [
    "#create a function \n",
    "def make_Dictionary(root_dir):\n",
    "#create an empty list to store the words from the emails\n",
    "  all_words = []\n",
    "#creates a list of full file paths for each email in root_dir\n",
    "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n",
    "#this for loop iterates over each email in the file \n",
    "  for mail in emails:\n",
    "    with open(mail) as m:\n",
    "#read email line by line and splits into words\n",
    "      for line in m:\n",
    "        words = line.split()\n",
    "#adds each word into the empty list all_words\n",
    "        all_words += words\n",
    "# use Counter to count how often each word appears in the all_words lsit\n",
    "  dictionary = Counter(all_words)\n",
    "#creates a list of all unique words. \n",
    "  list_to_remove = list(dictionary)\n",
    "#for loops iterates through each of the words in list_to_remove\n",
    "  for item in list_to_remove:\n",
    "#remove non-alphabetical characters\n",
    "    if item.isalpha() == False:\n",
    "      del dictionary[item]\n",
    "#remove single charcater words \n",
    "    elif len(item) == 1:\n",
    "      del dictionary[item]\n",
    "# Select the top 3,000 most common words from the dictionary and sortes them based on their frequency. Converts the Counter object into a list of (word, count) tuples.\n",
    "  dictionary = dictionary.most_common(3000)\n",
    "  return dictionary\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dmVW5xNlyOFc"
   },
   "outputs": [],
   "source": [
    "def extract_features(mail_dir):\n",
    "# get a list of email file paths in the specified directory\n",
    "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
    "#structures the emails so each row is an email and columns are the 3000 words \n",
    "  features_matrix = np.zeros((len(files),3000))\n",
    "#numpy array is initialized which will ater be used to identify if an email is spam or not \n",
    "  train_labels = np.zeros(len(files))\n",
    "  count = 1; #counter to track number of spam emails\n",
    "  docID = 0; #index in the matrix\n",
    "#iterate over each email file\n",
    "  for fil in files:\n",
    "#open the file and automatically closes it. Helps w data protections\n",
    "    with open(fil) as fi:\n",
    "# read each email line by line\n",
    "      for i, line in enumerate(fi):\n",
    "        if i ==2: #words from the third line are extracted. contains body of the email\n",
    "          words = line.split()\n",
    "          for word in words:\n",
    "            wordID = 0 #initialize the word index \n",
    "              #check if the word exists in the email\n",
    "            for i, d in enumerate(dictionary):\n",
    "              if d[0] == word: #if the word is found\n",
    "                wordID = i #get its index\n",
    "                  #store the word count in the matrix\n",
    "                features_matrix[docID,wordID] = words.count(word)\n",
    "        #0=no spam\n",
    "      train_labels[docID] = 0;\n",
    "        #extract file name from file path\n",
    "      filepathTokens = fil.split('/')\n",
    "        #takes the last item in the file path. i.e. spmsg1.txt\n",
    "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
    "    #if the last item starts with spmsg then it is considered spam\n",
    "      if lastToken.startswith(\"spmsg\"):\n",
    "        train_labels[docID] = 1; #label spam emails with 1\n",
    "        count = count + 1 #increment spam email count\n",
    "      docID = docID + 1 #move to the next email \n",
    "  return features_matrix, train_labels                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zoq-rE7Mx0pp"
   },
   "outputs": [],
   "source": [
    "# Enter the \"path\" of your \"train_mails\" and \"test-mails\" FOLDERS in this cell ...\n",
    "# for example: TRAIN_DIR = '../../train-mails'\n",
    "#              TEST_DIR = '../../test-mails'\n",
    "TRAIN_DIR = r'/Users/sofiabrown/Desktop/BSAN 6070/CA02/train-mails'\n",
    "TEST_DIR = r'/Users/sofiabrown/Desktop/BSAN 6070/CA02/test-mails'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 127480,
     "status": "ok",
     "timestamp": 1578886833446,
     "user": {
      "displayName": "Arin Brahma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBXGIW7FvUnbm_QmEFGh4rLebuLHNZgc8PuNinU=s64",
      "userId": "05299564422021375910"
     },
     "user_tz": 480
    },
    "id": "134lmhauyQxE",
    "outputId": "83cce6a6-aff5-4e93-ef0a-700606437aa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading and processing emails from TRAIN and TEST folders\n"
     ]
    }
   ],
   "source": [
    "dictionary = make_Dictionary(TRAIN_DIR)\n",
    "\n",
    "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
    "features_matrix, labels = extract_features(TRAIN_DIR)\n",
    "test_features_matrix, test_labels = extract_features(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 127480,
     "status": "ok",
     "timestamp": 1578886833446,
     "user": {
      "displayName": "Arin Brahma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBXGIW7FvUnbm_QmEFGh4rLebuLHNZgc8PuNinU=s64",
      "userId": "05299564422021375910"
     },
     "user_tz": 480
    },
    "id": "134lmhauyQxE",
    "outputId": "83cce6a6-aff5-4e93-ef0a-700606437aa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed\n",
      "Testing trained model to predict Test Data labels\n",
      "Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
      "0.9615384615384616\n"
     ]
    }
   ],
   "source": [
    "# In this section enter your code to TRAIN the model using Naive Bayes algorithm, then PREDICT and then evaluate PERFORMANCE (Accuracy)\n",
    "# Your code below ...\n",
    "#initialize model\n",
    "nb_model=MultinomialNB()\n",
    "\n",
    "#train the model on training data\n",
    "nb_model.fit(features_matrix, labels)\n",
    "\n",
    "print(\"Training completed\")\n",
    "\n",
    "print(\"Testing trained model to predict Test Data labels\")\n",
    "predicted_labels = nb_model.predict(test_features_matrix)\n",
    "\n",
    "print(\"Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\")\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M5_mPrvN586A"
   },
   "source": [
    "======================= END OF PROGRAM ========================="
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOaSi3qlFUlqTup/1esXCKD",
   "collapsed_sections": [],
   "name": "naive_bayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
